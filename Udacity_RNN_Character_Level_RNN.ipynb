{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/anna.txt') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: By using **set**, a set of all unique characters is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length:  1985223\n",
      "Number of Characters:  83\n"
     ]
    }
   ],
   "source": [
    "chars=set(text)\n",
    "print('Text Length: ',len(text))\n",
    "print('Number of Characters: ',len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=tuple(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: A dictionary is created by adding an index to the set of unique characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2dict=dict(enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'J', 1: 'a', 2: 'N', 3: 'g', 4: '_', 5: '(', 6: 'b', 7: 'e', 8: 'A', 9: 'r', 10: '5', 11: 'G', 12: 'I', 13: 'd', 14: '0', 15: '3', 16: 'S', 17: ',', 18: '@', 19: 'K', 20: '.', 21: ')', 22: 'D', 23: '2', 24: 'R', 25: 'Y', 26: 'H', 27: 'B', 28: 'O', 29: '!', 30: 'L', 31: 'P', 32: '4', 33: 't', 34: 'j', 35: 'y', 36: 'l', 37: '&', 38: '6', 39: 'Z', 40: '%', 41: 'p', 42: '?', 43: 'h', 44: 'i', 45: 'M', 46: 'f', 47: 'v', 48: ';', 49: '`', 50: 'w', 51: '7', 52: 'V', 53: 'x', 54: 'c', 55: '1', 56: 'q', 57: 's', 58: \"'\", 59: '$', 60: 'F', 61: '8', 62: 'U', 63: '9', 64: '*', 65: 'k', 66: '\"', 67: 'u', 68: '/', 69: 'z', 70: 'C', 71: '\\n', 72: 'T', 73: 'W', 74: ' ', 75: 'X', 76: 'o', 77: 'n', 78: 'E', 79: 'm', 80: '-', 81: 'Q', 82: ':'}\n"
     ]
    }
   ],
   "source": [
    "print(int2dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Index and character are switched. Thus, the text can be encoded to integer values by\n",
    "using the character as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int={ch: ind for ind,ch in int2dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'J': 0, 'a': 1, 'N': 2, 'g': 3, '_': 4, '(': 5, 'b': 6, 'e': 7, 'A': 8, 'r': 9, '5': 10, 'G': 11, 'I': 12, 'd': 13, '0': 14, '3': 15, 'S': 16, ',': 17, '@': 18, 'K': 19, '.': 20, ')': 21, 'D': 22, '2': 23, 'R': 24, 'Y': 25, 'H': 26, 'B': 27, 'O': 28, '!': 29, 'L': 30, 'P': 31, '4': 32, 't': 33, 'j': 34, 'y': 35, 'l': 36, '&': 37, '6': 38, 'Z': 39, '%': 40, 'p': 41, '?': 42, 'h': 43, 'i': 44, 'M': 45, 'f': 46, 'v': 47, ';': 48, '`': 49, 'w': 50, '7': 51, 'V': 52, 'x': 53, 'c': 54, '1': 55, 'q': 56, 's': 57, \"'\": 58, '$': 59, 'F': 60, '8': 61, 'U': 62, '9': 63, '*': 64, 'k': 65, '\"': 66, 'u': 67, '/': 68, 'z': 69, 'C': 70, '\\n': 71, 'T': 72, 'W': 73, ' ': 74, 'X': 75, 'o': 76, 'n': 77, 'E': 78, 'm': 79, '-': 80, 'Q': 81, ':': 82}\n"
     ]
    }
   ],
   "source": [
    "print(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Encode text from characters to numbers. Generate a Numpy array out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded=np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 43  1 ... 57 20 71]\n"
     ]
    }
   ],
   "source": [
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 43  1 41 33  7  9 74 55 71 71 71 26  1 41 41 35 74 46  1 79 44 36 44\n",
      "  7 57 74  1  9  7 74  1 36 36 74  1 36 44 65  7 48 74  7 47  7  9 35 74\n",
      " 67 77 43  1 41 41 35 74 46  1 79 44 36 35 74 44 57 74 67 77 43  1 41 41\n",
      " 35 74 44 77 74 44 33 57 74 76 50 77 71 50  1 35 20 71 71 78 47  7  9 35\n",
      " 33 43 44 77]\n"
     ]
    }
   ],
   "source": [
    "print(encoded[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data: One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Generate function for one hot encoding. For every integer value from our dictionary a \n",
    "vector is generated. The number of labels (n_labels) corresponds to the length of our char2int-\n",
    "dictionary and the number of columns in this new vector. The vector will be a row vector in which all values will be zero except one. This will be one. This value of one is on the position of the key of the character in our dictionary.\n",
    "\n",
    "Example text: aba aaaac bbba accb\n",
    "Dictionary: {'a':0,'b':1,'c':2}\n",
    "\n",
    "One Hot vector length = 3 ([000])    => (there are 3 different characters in our example text)<br>\n",
    "First letter [100]                   => (key 'a' has value 0 in our dictionary), second letter [010] and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    len_seq=len(arr[0])\n",
    "    row_ct=len_seq\n",
    "    one_hot=np.zeros((row_ct,n_labels),dtype=np.float32)\n",
    "    print('One Hot Shape: ',one_hot.shape)\n",
    "    one_hot[np.arange(row_ct),arr.flatten()]=1.\n",
    "    one_hot=one_hot.reshape(*arr.shape,n_labels)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Test:* One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "test_sequence=np.array([[1,2,5,4,3]])\n",
    "one_hot_result=one_hot_encode(test_sequence,8)\n",
    "print(one_hot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr,batch_size,seq_length):\n",
    "    ''' Create a generator that returns batches of size \n",
    "        batch_size x seq_length from arr.\n",
    "        \n",
    "        Arguments:\n",
    "        arr: text\n",
    "        batch_size: Batch size = number of sequences per batch\n",
    "        seq_lenght: Number of encoded chars in a sequence'''\n",
    "    \n",
    "    #Convert parameters to integer\n",
    "    batch_size=int(batch_size)\n",
    "    seq_length=int(seq_length)\n",
    "    \n",
    "    #Calculate total size of one batch (N x M where N=number of batches and M=seq_length)\n",
    "    #Equal to number of characters in one batch\n",
    "    batch_size_total=int(seq_length*batch_size)\n",
    "    #Calculate number of batches in whole text by dividing number of all characters\n",
    "    #by number of characters in one batch\n",
    "    n_batches=len(arr)//batch_size_total\n",
    "    print('Number of batches: ',n_batches)\n",
    "    print('Total batch size: ',batch_size_total)\n",
    "    #In the end, the text has to be cut. This means, that the characters at the end of the\n",
    "    #text will be discarded because they will not fit in one whole batch and thus would\n",
    "    #insert errors. The first character which will not fit in a batch anymore can be\n",
    "    #computed by simply multiplying number of batches with number of characters per batch\n",
    "    last_char=int(n_batches*batch_size_total)\n",
    "    print('Characters that fit in batches: ',last_char)\n",
    "    print('Original text: ',len(arr))\n",
    "        \n",
    "    #Slice text and cut off characters that do not fit in the last batch anymore.\n",
    "    #So, every character is in one batch at the end.\n",
    "    arr=arr[:last_char]\n",
    "    \n",
    "    #Text is reshaped now that only the characters fitting in one batch are left\n",
    "    #The number of rows = number of batches (hyperparameter)\n",
    "    #The number of columns depends on the batch_size and on the length of the whole text\n",
    "    #(-1) allows this number of columns to be adjusted dynamically\n",
    "    arr=arr.reshape((batch_size,-1))\n",
    "    \n",
    "    #Print Shape of final array which will be used for batch generation\n",
    "    print('Arr-Shape', arr.shape)\n",
    "    print('Number of Rows in total/one batch = Arr-Shape of Dimension 0: ', arr.shape[0])\n",
    "    print('Number of Columns in total = Arr-Shape of Dimension 1:',arr.shape[1])\n",
    "    print('Number of Columns in one batch = Seq-Length (Window size, x-Dimension): ', seq_length)\n",
    "    \n",
    "    number_columns_text=arr.shape[1]\n",
    "    number_columns_batch=seq_length\n",
    "    \n",
    "    for n in range(0,number_columns_text,number_columns_batch):\n",
    "        \n",
    "        #Features (Characters)\n",
    "        x=arr[:,n:n+number_columns_batch]\n",
    "        print('x-Shape: ',x.shape)\n",
    "        y=np.zeros_like(x)\n",
    "        print('y-Shape: ',x.shape)\n",
    "        print(y)\n",
    "        try:\n",
    "            y[:,:-1],y[:,-1]=x[:,1:],arr[:,n+number_columns_batch]\n",
    "        except IndexError:\n",
    "            y[:,:-1],y[:,-1]=x[:,1:],arr[:0]\n",
    "        print('Cycle: ',n)\n",
    "        print('X:',x)\n",
    "        print('Y:',y)\n",
    "        yield x,y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Batch Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  4963\n",
      "Total batch size:  400\n",
      "Characters that fit in batches:  1985200\n",
      "Original text:  1985223\n",
      "Arr-Shape (8, 248150)\n",
      "Number of Rows in total/one batch = Arr-Shape of Dimension 0:  8\n",
      "Number of Columns in total = Arr-Shape of Dimension 1: 248150\n",
      "Number of Columns in one batch = Seq-Length (Window size, x-Dimension):  50\n",
      "x-Shape:  (8, 50)\n",
      "y-Shape:  (8, 50)\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Cycle:  0\n",
      "X: [[70 43  1 41 33  7  9 74 55 71 71 71 26  1 41 41 35 74 46  1 79 44 36 44\n",
      "   7 57 74  1  9  7 74  1 36 36 74  1 36 44 65  7 48 74  7 47  7  9 35 74\n",
      "  67 77]\n",
      " [57 76 77 74 33 43  1 33 74  1 33 33  9  1 54 33  7 13 74 43  7  9 74  1\n",
      "  33 33  7 77 33 44 76 77 74 50  1 57 74 43  7  9 74 43 67 57  6  1 77 13\n",
      "  20 74]\n",
      " [ 7 77 13 74 76  9 74  1 74 46 76  7 17 74 43  7 74  1 47 76 44 13  7 13\n",
      "  74 43 44 57 74 46  1 33 43  7  9 20 74 26  7 71 36 76 76 65  7 13 74  9\n",
      "  76 67]\n",
      " [57 74 33 43  7 74 54 43 44  7 46 74 33 43 76 67  3 43 74 43 44 13 13  7\n",
      "  77 71 44 77 33  7  9  7 57 33 74 76 46 74 43 44 57 74 36 44 46  7 17 74\n",
      "  76 46]\n",
      " [74 57  1 50 74 43  7  9 74 33  7  1  9 80 57 33  1 44 77  7 13 17 74 41\n",
      "  44 33 44 46 67 36 17 74 57 50  7  7 33 74 46  1 54  7 17 71 79 44 57  7\n",
      "   9  1]\n",
      " [54 67 57 57 44 76 77 74  1 77 13 74  1 77  1 36 35 57 44 57 17 74 50  1\n",
      "  57 74 44 77 74 41  9 44 77 54 44 41 36  7 74 13 44 57  1  3  9  7  7  1\n",
      "   6 36]\n",
      " [74  8 77 77  1 74 43  1 13 74 57  1 44 13 74 33 43  1 33 74 22 76 36 36\n",
      "  35 74 50 76 67 36 13 74  7 53 54 67 57  7 74 44 33 20 74  8 77 13 74 33\n",
      "  43 44]\n",
      " [28  6 36 76 77 57 65 35 20 74 66 27 67 33 74  4 33 43  7 35  4 74 54  1\n",
      "  77 77 76 33 74  3  9  1 57 41 74 33 43  1 33 17 71  4 33 43  7 35  4 74\n",
      "   1  9]]\n",
      "Y: [[43  1 41 33  7  9 74 55 71 71 71 26  1 41 41 35 74 46  1 79 44 36 44  7\n",
      "  57 74  1  9  7 74  1 36 36 74  1 36 44 65  7 48 74  7 47  7  9 35 74 67\n",
      "  77 43]\n",
      " [76 77 74 33 43  1 33 74  1 33 33  9  1 54 33  7 13 74 43  7  9 74  1 33\n",
      "  33  7 77 33 44 76 77 74 50  1 57 74 43  7  9 74 43 67 57  6  1 77 13 20\n",
      "  74 66]\n",
      " [77 13 74 76  9 74  1 74 46 76  7 17 74 43  7 74  1 47 76 44 13  7 13 74\n",
      "  43 44 57 74 46  1 33 43  7  9 20 74 26  7 71 36 76 76 65  7 13 74  9 76\n",
      "  67 77]\n",
      " [74 33 43  7 74 54 43 44  7 46 74 33 43 76 67  3 43 74 43 44 13 13  7 77\n",
      "  71 44 77 33  7  9  7 57 33 74 76 46 74 43 44 57 74 36 44 46  7 17 74 76\n",
      "  46 74]\n",
      " [57  1 50 74 43  7  9 74 33  7  1  9 80 57 33  1 44 77  7 13 17 74 41 44\n",
      "  33 44 46 67 36 17 74 57 50  7  7 33 74 46  1 54  7 17 71 79 44 57  7  9\n",
      "   1  6]\n",
      " [67 57 57 44 76 77 74  1 77 13 74  1 77  1 36 35 57 44 57 17 74 50  1 57\n",
      "  74 44 77 74 41  9 44 77 54 44 41 36  7 74 13 44 57  1  3  9  7  7  1  6\n",
      "  36  7]\n",
      " [ 8 77 77  1 74 43  1 13 74 57  1 44 13 74 33 43  1 33 74 22 76 36 36 35\n",
      "  74 50 76 67 36 13 74  7 53 54 67 57  7 74 44 33 20 74  8 77 13 74 33 43\n",
      "  44 57]\n",
      " [ 6 36 76 77 57 65 35 20 74 66 27 67 33 74  4 33 43  7 35  4 74 54  1 77\n",
      "  77 76 33 74  3  9  1 57 41 74 33 43  1 33 17 71  4 33 43  7 35  4 74  1\n",
      "   9  7]]\n"
     ]
    }
   ],
   "source": [
    "batches=get_batches(encoded,8,50)\n",
    "x,y=next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70 43  1 41 33  7  9 74 55 71]\n",
      " [57 76 77 74 33 43  1 33 74  1]\n",
      " [ 7 77 13 74 76  9 74  1 74 46]\n",
      " [57 74 33 43  7 74 54 43 44  7]\n",
      " [74 57  1 50 74 43  7  9 74 33]\n",
      " [54 67 57 57 44 76 77 74  1 77]\n",
      " [74  8 77 77  1 74 43  1 13 74]\n",
      " [28  6 36 76 77 57 65 35 20 74]]\n",
      "[[43  1 41 33  7  9 74 55 71 71]\n",
      " [76 77 74 33 43  1 33 74  1 33]\n",
      " [77 13 74 76  9 74  1 74 46 76]\n",
      " [74 33 43  7 74 54 43 44  7 46]\n",
      " [57  1 50 74 43  7  9 74 33  7]\n",
      " [67 57 57 44 76 77 74  1 77 13]\n",
      " [ 8 77 77  1 74 43  1 13 74 57]\n",
      " [ 6 36 76 77 57 65 35 20 74 66]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:10,:10])\n",
    "print(y[:10,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Test Batch Making:* Is Matrix Y shifted by one character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It worked. Frame is shifted. Y matrix is one step ahead of matrix X.\n"
     ]
    }
   ],
   "source": [
    "test=0\n",
    "if x[:1,1]==y[:1,0]:\n",
    "    if x[2:3,5]==y[2:3,4]:\n",
    "        if x[3:4,8]==y[3:4,7]:\n",
    "            print(\"It worked. Frame is shifted. Y matrix is one step ahead of matrix X.\")\n",
    "            test=1\n",
    "if test==0:\n",
    "    print(\"Frame shift of y matrix did not work. Please review matrix Y generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Network with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Move to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. CPU training!\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "if (train_on_gpu):\n",
    "    print('GPU detected. Will train on GPU!')\n",
    "else:\n",
    "    print('No GPU detected. CPU training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define Architecture of Character-Level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.drop_prob=drop_prob\n",
    "        self.n_layers=n_layers\n",
    "        self.n_hidden=n_hidden\n",
    "        self.lr=lr\n",
    "        \n",
    "        self.chars=tokens\n",
    "        self.int2char=dict(enumerate(self.chars))\n",
    "        self.char2int={ch: ii for ii,ch in self.int2char.items()}\n",
    "        \n",
    "        self.lstm=nn.LSTM(len(self.chars), n_hidden,n_layers,dropout=drop_prob,batch_first=True)\n",
    "        self.dropout=nn.Dropout(drop_prob)\n",
    "        self.fc=nn.Linear(n_hidden,len(self.chars))\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        \n",
    "        r_output,hidden=self.lstm(x,hidden)\n",
    "        out=self.dropout(r_output)\n",
    "        #Stack LSTM layers\n",
    "        out=out.contiguous().view(-1,self.n_hidden)\n",
    "        out=self.fc(out)\n",
    "        \n",
    "        return out,hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        weight=next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "             hidden=(weight.new(self.n_layers,batch_size,self.n_hidden).zero().cuda(),\n",
    "                     weight.new(self.n_layers,batch_size,self.n_hidden).zero().cuda())\n",
    "        else:\n",
    "             hidden=(weight.new(self.n_layers,batch_size,self.n_hidden).zero_(),\n",
    "                     weight.new(self.n_layers,batch_size,self.n_hidden).zero_()) \n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(net,data,epochs=1,batch_size=10,seq_length=50,lr=0.001,\n",
    "              clip=5,val_frac=0,print_every=10):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    #Define Hyperparameters Criterion,Optimizer\n",
    "    opt=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    \n",
    "    #Split in Trainiing and Validation Data\n",
    "    #val_frac=percentage of validation set (0.1=10%)\n",
    "    val_idx=int(len(data)*(1-val_frac))\n",
    "    data,val_data=data[:val_idx],data[:]\n",
    "    \n",
    "    #Move to GPU if available\n",
    "    if train_on_gpu:\n",
    "        net.cuda()\n",
    "    \n",
    "    counter=0\n",
    "    n_chars=len(net.chars)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        #initialize hidden state\n",
    "        h=net.init_hidden(batch_size)\n",
    "        \n",
    "        for x,y in get_batches(data,batch_size,seq_length):\n",
    "            \n",
    "            #Epoch counter\n",
    "            counter+=1\n",
    "            \n",
    "            #One Hot Encoding\n",
    "            print('x: ',x.shape)\n",
    "            print('n_chars: ',n_chars)\n",
    "            x=one_hot_encode(x,n_chars)\n",
    "            #Tranform Numpy arrays to tensors for input to network\n",
    "            inputs,targets=torch.from_numpy(x),torch.from_numpy(y)\n",
    "            \n",
    "            #Move to GPU if available\n",
    "            if train_on_gpu:\n",
    "                inputs,targets=inputs.cuda(),targets.cuda()\n",
    "            \n",
    "            #Create new, empty hidden state to loose history\n",
    "            h=tuple([each.data for each in h])\n",
    "            \n",
    "            #Delete Gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            #Forward Pass\n",
    "            output,h=net(inputs,h)\n",
    "            \n",
    "            #Cost\n",
    "            loss=criterion(output,targets.view(batch_size*seq_length))\n",
    "            \n",
    "            #Backpropation\n",
    "            loss.backward() \n",
    "            nn.utils.clip_grad_norm(net.parameters(),clip)\n",
    "            opt.step()\n",
    "            \n",
    "            if counter%print_every==0:\n",
    "                \n",
    "                val_hidden=net.init_hidden(batch_size)\n",
    "                val_losses=[]\n",
    "                \n",
    "                net.eval()\n",
    "                \n",
    "                for x,y in get_batches(data,batch_size,seq_length):\n",
    "                    \n",
    "                    #One Hot Encoding\n",
    "                    x=one_hot_encode(x,n_chars)\n",
    "                    \n",
    "                    #Transform Numpy arrays to tensors for input to network\n",
    "                    x,y=torch.from_numpy(x),torch.from_numpy(y)\n",
    "                    \n",
    "                    if train_on_gpu:\n",
    "                        inputs,targets=inputs.cuda(),targets.cuda()\n",
    "                    \n",
    "                    val_hidden=tuple([each.data for each in data])\n",
    "                    \n",
    "                    #Forward Pass\n",
    "                    output,val_hidden=net(inputs,val_hidden)\n",
    "                    \n",
    "                    #Cost\n",
    "                    val_loss=criterion(output,targets.view(batch_size*seq_length))\n",
    "                    \n",
    "                    #Extend list with validation losses\n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train()\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1,epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:,.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=256\n",
    "n_layers=2\n",
    "\n",
    "net=CharRNN(chars,n_hidden,n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters and Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  4963\n",
      "Total batch size:  400\n",
      "Characters that fit in batches:  1985200\n",
      "Original text:  1985223\n",
      "Arr-Shape (8, 248150)\n",
      "Number of Rows in total/one batch = Arr-Shape of Dimension 0:  8\n",
      "Number of Columns in total = Arr-Shape of Dimension 1: 248150\n",
      "Number of Columns in one batch = Seq-Length (Window size, x-Dimension):  50\n",
      "x-Shape:  (8, 50)\n",
      "y-Shape:  (8, 50)\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Cycle:  0\n",
      "X: [[70 43  1 41 33  7  9 74 55 71 71 71 26  1 41 41 35 74 46  1 79 44 36 44\n",
      "   7 57 74  1  9  7 74  1 36 36 74  1 36 44 65  7 48 74  7 47  7  9 35 74\n",
      "  67 77]\n",
      " [57 76 77 74 33 43  1 33 74  1 33 33  9  1 54 33  7 13 74 43  7  9 74  1\n",
      "  33 33  7 77 33 44 76 77 74 50  1 57 74 43  7  9 74 43 67 57  6  1 77 13\n",
      "  20 74]\n",
      " [ 7 77 13 74 76  9 74  1 74 46 76  7 17 74 43  7 74  1 47 76 44 13  7 13\n",
      "  74 43 44 57 74 46  1 33 43  7  9 20 74 26  7 71 36 76 76 65  7 13 74  9\n",
      "  76 67]\n",
      " [57 74 33 43  7 74 54 43 44  7 46 74 33 43 76 67  3 43 74 43 44 13 13  7\n",
      "  77 71 44 77 33  7  9  7 57 33 74 76 46 74 43 44 57 74 36 44 46  7 17 74\n",
      "  76 46]\n",
      " [74 57  1 50 74 43  7  9 74 33  7  1  9 80 57 33  1 44 77  7 13 17 74 41\n",
      "  44 33 44 46 67 36 17 74 57 50  7  7 33 74 46  1 54  7 17 71 79 44 57  7\n",
      "   9  1]\n",
      " [54 67 57 57 44 76 77 74  1 77 13 74  1 77  1 36 35 57 44 57 17 74 50  1\n",
      "  57 74 44 77 74 41  9 44 77 54 44 41 36  7 74 13 44 57  1  3  9  7  7  1\n",
      "   6 36]\n",
      " [74  8 77 77  1 74 43  1 13 74 57  1 44 13 74 33 43  1 33 74 22 76 36 36\n",
      "  35 74 50 76 67 36 13 74  7 53 54 67 57  7 74 44 33 20 74  8 77 13 74 33\n",
      "  43 44]\n",
      " [28  6 36 76 77 57 65 35 20 74 66 27 67 33 74  4 33 43  7 35  4 74 54  1\n",
      "  77 77 76 33 74  3  9  1 57 41 74 33 43  1 33 17 71  4 33 43  7 35  4 74\n",
      "   1  9]]\n",
      "Y: [[43  1 41 33  7  9 74 55 71 71 71 26  1 41 41 35 74 46  1 79 44 36 44  7\n",
      "  57 74  1  9  7 74  1 36 36 74  1 36 44 65  7 48 74  7 47  7  9 35 74 67\n",
      "  77 43]\n",
      " [76 77 74 33 43  1 33 74  1 33 33  9  1 54 33  7 13 74 43  7  9 74  1 33\n",
      "  33  7 77 33 44 76 77 74 50  1 57 74 43  7  9 74 43 67 57  6  1 77 13 20\n",
      "  74 66]\n",
      " [77 13 74 76  9 74  1 74 46 76  7 17 74 43  7 74  1 47 76 44 13  7 13 74\n",
      "  43 44 57 74 46  1 33 43  7  9 20 74 26  7 71 36 76 76 65  7 13 74  9 76\n",
      "  67 77]\n",
      " [74 33 43  7 74 54 43 44  7 46 74 33 43 76 67  3 43 74 43 44 13 13  7 77\n",
      "  71 44 77 33  7  9  7 57 33 74 76 46 74 43 44 57 74 36 44 46  7 17 74 76\n",
      "  46 74]\n",
      " [57  1 50 74 43  7  9 74 33  7  1  9 80 57 33  1 44 77  7 13 17 74 41 44\n",
      "  33 44 46 67 36 17 74 57 50  7  7 33 74 46  1 54  7 17 71 79 44 57  7  9\n",
      "   1  6]\n",
      " [67 57 57 44 76 77 74  1 77 13 74  1 77  1 36 35 57 44 57 17 74 50  1 57\n",
      "  74 44 77 74 41  9 44 77 54 44 41 36  7 74 13 44 57  1  3  9  7  7  1  6\n",
      "  36  7]\n",
      " [ 8 77 77  1 74 43  1 13 74 57  1 44 13 74 33 43  1 33 74 22 76 36 36 35\n",
      "  74 50 76 67 36 13 74  7 53 54 67 57  7 74 44 33 20 74  8 77 13 74 33 43\n",
      "  44 57]\n",
      " [ 6 36 76 77 57 65 35 20 74 66 27 67 33 74  4 33 43  7 35  4 74 54  1 77\n",
      "  77 76 33 74  3  9  1 57 41 74 33 43  1 33 17 71  4 33 43  7 35  4 74  1\n",
      "   9  7]]\n",
      "x:  (8, 50)\n",
      "n_chars:  83\n",
      "One Hot Shape:  (50, 83)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (50,) (400,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-972ed535a43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_rnn(net,encoded,epochs=n_epochs,batch_size=batch_size,seq_length=seq_length,\n\u001b[0;32m----> 6\u001b[0;31m      lr=0.001,print_every=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-122-ffde220d196b>\u001b[0m in \u001b[0;36mtrain_rnn\u001b[0;34m(net, data, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_chars: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;31m#Tranform Numpy arrays to tensors for input to network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-ed5640f19108>\u001b[0m in \u001b[0;36mone_hot_encode\u001b[0;34m(arr, n_labels)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_ct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'One Hot Shape: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_ct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (50,) (400,) "
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "seq_length=50\n",
    "n_epochs=1\n",
    "\n",
    "train_rnn(net,encoded,epochs=n_epochs,batch_size=batch_size,seq_length=seq_length,\n",
    "     lr=0.001,print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Udacity_DL_CNN_01_Start",
   "language": "python",
   "name": "udacity_dl_cnn_01_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
